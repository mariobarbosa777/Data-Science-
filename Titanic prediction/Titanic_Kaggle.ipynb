{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "from sklearn import preprocessing \n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer Los datos\n",
    "df_train = pd.read_csv(\"data/train.csv\", index_col=\"PassengerId\")\n",
    "df_test = pd.read_csv(\"data/test.csv\", index_col=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Borrar Variables\n",
    "df_train.drop(columns=[\"Name\",\"Cabin\",\"Ticket\"], inplace=True);\n",
    "df_test.drop(columns=[\"Name\",\"Cabin\",\"Ticket\"], inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir a tipos de variable adecuados \n",
    "df_train.convert_dtypes();\n",
    "df_test.convert_dtypes();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar o Borrar valores NAN\n",
    "\n",
    "df_train.fillna(df_train.median(), inplace=True)\n",
    "#df_train.dropna(inplace=True)\n",
    "df_test.fillna(df_train.median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducir dimensionalidad encontrado correlaci√≥n de variables\n",
    "df_train[\"Family_members\"] = df_train[\"SibSp\"] + df_train[\"Parch\"]\n",
    "df_test[\"Family_members\"] = df_test[\"SibSp\"] + df_test[\"Parch\"]\n",
    "df_train.drop(columns=[\"SibSp\",\"Parch\"], inplace=True);\n",
    "df_test.drop(columns=[\"SibSp\",\"Parch\"], inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorizar variables  (Sex y Embarked)\n",
    "df_train[[\"Sex\"]] = df_train[[\"Sex\"]].astype(\"category\")\n",
    "df_test[[\"Sex\"]] = df_test[[\"Sex\"]].astype(\"category\")\n",
    "\n",
    "df_train[[\"Embarked\"]] = df_train[[\"Embarked\"]].astype(\"category\")\n",
    "df_test[[\"Embarked\"]] = df_test[[\"Embarked\"]].astype(\"category\")\n",
    "\n",
    "# Obtener dummis de variables categoricas \n",
    "df_train[[\"IsWomen\",\"IsMan\"]] = pd.get_dummies(df_train[[\"Sex\"]])\n",
    "df_test[[\"IsWomen\",\"IsMan\"]] = pd.get_dummies(df_test[[\"Sex\"]])\n",
    "\n",
    "df_train[[\"IsC\",\"IsQ\",\"IsS\"]] = pd.get_dummies(df_train[[\"Embarked\"]])\n",
    "df_test[[\"IsC\",\"IsQ\",\"IsS\"]] = pd.get_dummies(df_test[[\"Embarked\"]])\n",
    "\n",
    "# Borrar Dummies Sobrantes y Variables Categoricas Originales \n",
    "df_train.drop(columns=[\"IsMan\",\"Sex\",\"IsQ\",\"Embarked\"], inplace=True);\n",
    "df_test.drop(columns=[\"IsMan\",\"Sex\",\"IsQ\",\"Embarked\"], inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupar datos numericos \n",
    "\n",
    "#( ] ( ] ( ] ( ] ( ]\n",
    "\n",
    "#0.8061\n",
    "bins = [-10, 0, 5, 12, 32, 60, 100]\n",
    "names = [1, 2, 3, 4, 5, 6] \n",
    "\n",
    "#Age \n",
    "df_train[\"Age\"]=pd.cut( df_train[\"Age\"], bins =bins, labels = names)\n",
    "df_test[\"Age\"]=pd.cut( df_test[\"Age\"], bins =bins, labels = names )\n",
    "\n",
    "df_train[\"Age\"]=df_train.Age.astype('category').cat.codes\n",
    "df_test[\"Age\"]=df_test.Age.astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3    554\n4    246\n1     44\n2     25\n5     22\nName: Age, dtype: int64"
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "df_train.Age.value_counts()\n",
    "\n",
    "#df_train[df_train.Age==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficas\n",
    "sns.boxplot(data = df_train._get_numeric_data())\n",
    " \n",
    "#pair map\n",
    "sns.pairplot(df_train, hue=\"Survived\", plot_kws={'alpha':0.3} )\n",
    "\n",
    "# corr \n",
    "corr= df_train._get_numeric_data().corr()\n",
    "sns.heatmap(corr, yticklabels = corr.columns, xticklabels = corr.columns,  annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning\n",
    "\n",
    "# X = Features Y = Target \n",
    "X = df_train.drop(columns=['Survived'])\n",
    "Y = df_train['Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifiers_dict = {    #\"RandomForest\"          :RandomForestClassifier(),\n",
    "                        \"GradientBoosting\"      :GradientBoostingClassifier(n_estimators=110),\n",
    "                        # \"KNeighborsClassifier\"  :KNeighborsClassifier(),\n",
    "                        # \"DecisionTreeClassifier\":DecisionTreeClassifier(),\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "GradientBoosting\n\nTrain Mean = 0.8964621712340641\nTest Mean = 0.8305504990270542\nTrain MAX = 0.9144460028050491\nTest MAX = 0.8820224719101124\n[('Pclass', 0.1404), ('Age', 0.0726), ('Fare', 0.1998), ('Family_members', 0.0884), ('IsWomen', 0.4815), ('IsC', 0.0032), ('IsS', 0.0141)]\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
    }
   ],
   "source": [
    "for  Name, Classifier  in Classifiers_dict.items():\n",
    "    print(Name)\n",
    "    print()\n",
    "    CrossResults = cross_validate(Classifier, X, Y, cv=5, return_train_score=True)\n",
    "    print (f\"Train Mean = {np.mean(CrossResults['train_score'])}\")\n",
    "    print (f\"Test Mean = {np.mean(CrossResults['test_score'])}\" )\n",
    "    print (f\"Train MAX = {np.max(CrossResults['train_score'])}\")\n",
    "    print (f\"Test MAX = {np.max(CrossResults['test_score'])}\" )\n",
    "    \n",
    "    estimator = Classifier.fit(X,Y)\n",
    "    Y_test=estimator.predict(df_test)\n",
    "\n",
    "\n",
    "    try :\n",
    "        print (list(zip(X, np.round(estimator.feature_importances_,decimals=4))))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    df_salida = df_test.copy(deep=True)\n",
    "    df_salida['Survived'] = Y_test\n",
    "    df_salida.to_csv(f\"data/AAA__Titanic_{Name}_.csv\", index=True, columns=[\"Survived\"])\n",
    "\n",
    "    print(\"---\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n                           learning_rate=0.1, loss='deviance', max_depth=3,\n                           max_features=None, max_leaf_nodes=None,\n                           min_impurity_decrease=0.0, min_impurity_split=None,\n                           min_samples_leaf=1, min_samples_split=2,\n                           min_weight_fraction_leaf=0.0, n_estimators=100,\n                           n_iter_no_change=None, presort='deprecated',\n                           random_state=None, subsample=1.0, tol=0.0001,\n                           validation_fraction=0.1, verbose=0,\n                           warm_start=False)"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=5, error_score=nan,\n             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n                                                  criterion='friedman_mse',\n                                                  init=None, learning_rate=0.1,\n                                                  loss='deviance', max_depth=3,\n                                                  max_features='sqrt',\n                                                  max_leaf_nodes=None,\n                                                  min_impurity_decrease=0.0,\n                                                  min_impurity_split=None,\n                                                  min_samples_leaf=1,\n                                                  min_samples_split=2,\n                                                  min_weight_fraction_leaf=0.0,\n                                                  n_estimators=100,\n                                                  n_iter_no...nge=None,\n                                                  presort='deprecated',\n                                                  random_state=10, subsample=1,\n                                                  tol=0.0001,\n                                                  validation_fraction=0.1,\n                                                  verbose=0, warm_start=False),\n             iid=False, n_jobs=4,\n             param_grid={'learning_rate': [0.1, 0.05, 0.025, 0.01, 0.005,\n                                           0.001],\n                         'max_depth': range(3, 5),\n                         'n_estimators': range(100, 1000, 100)},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring='accuracy', verbose=0)"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "param_test1 = { \"learning_rate\":[0.1,0.05,0.025,0.01,0.005,0.001],\n",
    "                \"n_estimators\": range(100,1000,100),\n",
    "                \"max_depth\": range(3,5,1),\n",
    "                }\n",
    "\n",
    "estimator = GradientBoostingClassifier(min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10)\n",
    "\n",
    "gsearch1 = GridSearchCV( estimator,\n",
    "                         param_grid = param_test1,\n",
    "                         scoring=\"accuracy\",\n",
    "                         n_jobs=4,\n",
    "                         iid=False,\n",
    "                         cv=5)\n",
    "\n",
    "gsearch1.fit(X, Y) \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Grid: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 900} \n Best Score0.8406377502981608\n\nTrain Mean = 0.9169461209953196\nTest Mean = 0.8406377502981608\nTrain MAX = 0.9256661991584852\nTest MAX = 0.8707865168539326\n"
    }
   ],
   "source": [
    "print ( f\" Grid: {gsearch1.best_params_} \\n Best Score{gsearch1.best_score_}\" )\n",
    "final_results = cross_validate(gsearch1.best_estimator_, X , Y, cv=5, return_train_score=True)\n",
    "print(\"\")\n",
    "print (f\"Train Mean = {np.mean(final_results['train_score'])}\")\n",
    "print (f\"Test Mean = {np.mean(final_results['test_score'])}\" )\n",
    "print (f\"Train MAX = {np.max(final_results['train_score'])}\")\n",
    "print (f\"Test MAX = {np.max(final_results['test_score'])}\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_estimator = GradientBoostingClassifier(n_estimators=900,\n",
    "                                             learning_rate=0.01,\n",
    "                                             max_depth=3)\n",
    "final_estimator.fit(X,Y)\n",
    "\n",
    "Y_test=final_estimator.predict(df_test)\n",
    "\n",
    "df_salida = df_test.copy(deep=True)\n",
    "df_salida['Survived'] = Y_test\n",
    "df_salida.to_csv(\"data/ABB_GradientBoostingClassifier.csv\", index=True, columns=[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-345dd51542dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Survived\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "df_test=df_test.drop[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38132bitba50e9279d54427d9cf7a8c0a4119d93",
   "display_name": "Python 3.8.1 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}